{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SslnlBaKPeWP"
   },
   "source": [
    "# Wikipedia Semantic Search with Cohere Embedding Archives\n",
    "\n",
    "---\n",
    "## Introduction\n",
    "In this notebook, we demonstrate how to use the Bedrock Converse API to do simple [semantic search](https://txt.cohere.ai/what-is-semantic-search/) on the [Wikipedia embeddings archives](https://txt.cohere.ai/embedding-archives-wikipedia/) published by Cohere. These archives embed Wikipedia sites in multiple languages. In this example, we'll use [Wikipedia Simple English](https://huggingface.co/datasets/Cohere/wikipedia-22-12-simple-embeddings). \n",
    "\n",
    "## Semantic Search and Text Embeddings\n",
    "Semantic search leverages text embeddings and similarity to find responses based on meaning, not just keywords. Text embeddings represent pieces of text as numeric vectors that encode semantic meaning. It allows mathematical comparisons of word and sentence meaning. Multilingual embeddings enable semantic search across languages. The embedding maps text in different languages to the same vector space.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Getting Started\n",
    "\n",
    "### Step 0: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IUnwp2cYNnP0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cohere in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (5.5.8)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (1.34.101)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (1.9.4)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (0.27.0)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (0.9.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (2.8.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (0.19.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (2.32.0.20240622)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cohere) (4.10.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.101 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.0->cohere) (1.34.101)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.0->cohere) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.0->cohere) (0.10.1)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=1.9.2->cohere) (2.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tokenizers<1,>=0.15->cohere) (0.23.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.101->boto3<2.0.0,>=1.34.0->cohere) (2.9.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.101->boto3<2.0.0,>=1.34.0->cohere) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.32.101 requires botocore==1.34.101, but you have botocore 1.34.142 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Let's install \"cohere<5\" and HF datasets\n",
    "%pip install cohere\n",
    "%pip install datasets\n",
    "# Let's also install boto3\n",
    "%pip install boto3==1.34.120 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZds1apHPsag"
   },
   "source": [
    "Let's now download 1,000 records from the English Wikipedia embeddings archive so we can search it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "v8Pogz7gPQwg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import cohere\n",
    "\n",
    "# Add your cohere API key from www.cohere.com\n",
    "co = cohere.Client(\"JxNKCngko24WEtOQ3QpaJhzQgUNdwdD5SGuAXn7i\")  \n",
    "\n",
    "#Load at max 1000 documents + embeddings\n",
    "max_docs = 1000\n",
    "docs_stream = load_dataset(f\"Cohere/wikipedia-22-12-simple-embeddings\", split=\"train\", streaming=True)\n",
    "\n",
    "docs = []\n",
    "doc_embeddings = []\n",
    "\n",
    "for doc in docs_stream:\n",
    "    docs.append(doc)\n",
    "    doc_embeddings.append(doc['emb'])\n",
    "    if len(docs) >= max_docs:\n",
    "        break\n",
    "\n",
    "doc_embeddings = torch.tensor(doc_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIlx5RVCP7g7"
   },
   "source": [
    "Now, `doc_embeddings` holds the embeddings of the first 1,000 documents in the dataset. Each document is represented as an [embeddings vector](https://txt.cohere.ai/sentence-word-embeddings/) of 768 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBa3oxSsP2fv",
    "outputId": "d9d71135-7ac3-4424-d806-2a994a0b456a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbYAXaI4RQiH"
   },
   "source": [
    "We can now search these vectors for any query we want. For this toy example, we'll ask a question about Wikipedia since we know the Wikipedia page is included in the first 1000 documents we used here.\n",
    "\n",
    "To search, we embed the query, then get the nearest neighbors to its embedding (using dot product)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJGUurziNiYR",
    "outputId": "bb66def9-3d83-46f7-c871-1224eb5714cd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who founded Wikipedia\n",
      "Wikipedia\n",
      "Larry Sanger and Jimmy Wales are the ones who started Wikipedia. Wales is credited with defining the goals of the project. Sanger created the strategy of using a wiki to reach Wales' goal. On January 10, 2001, Larry Sanger proposed on the Nupedia mailing list to create a wiki as a \"feeder\" project for Nupedia. Wikipedia was launched on January 15, 2001. It was launched as an English-language edition at www.wikipedia.com, and announced by Sanger on the Nupedia mailing list. Wikipedia's policy of \"neutral point-of-view\" was enforced in its initial months, and was similar to Nupedia's earlier \"nonbiased\" policy. Otherwise, there weren't very many rules initially, and Wikipedia operated independently of Nupedia. \n",
      "\n",
      "Wikipedia\n",
      "Wikipedia began as a related project for Nupedia. Nupedia was a free English-language online encyclopedia project. Nupedia's articles were written and owned by Bomis, Inc which was a web portal company. The important people of the company were Jimmy Wales, the person in charge of Bomis, and Larry Sanger, the editor-in-chief of Nupedia. Nupedia was first licensed under the Nupedia Open Content License which was changed to the GNU Free Documentation License before Wikipedia was founded and made their first article when Richard Stallman requested them. \n",
      "\n",
      "Wikipedia\n",
      "Wikipedia was started on January 10, 2001, by Jimmy Wales and Larry Sanger as part of an earlier online encyclopedia named Nupedia. On January 15, 2001, Wikipedia became a separate website of its own. It is a wiki that uses the software MediaWiki (like all other Wikimedia Foundation projects). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the query, then embed it\n",
    "query = 'Who founded Wikipedia'\n",
    "response = co.embed(texts=[query], model='multilingual-22-12')\n",
    "query_embedding = response.embeddings \n",
    "query_embedding = torch.tensor(query_embedding)\n",
    "\n",
    "# Compute dot score between query embedding and document embeddings\n",
    "dot_scores = torch.mm(query_embedding, doc_embeddings.transpose(0, 1))\n",
    "top_k = torch.topk(dot_scores, k=3)\n",
    "\n",
    "# Print results\n",
    "print(\"Query:\", query)\n",
    "for doc_id in top_k.indices[0].tolist():\n",
    "    print(docs[doc_id]['title'])\n",
    "    print(docs[doc_id]['text'], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWFroOO2RwMd"
   },
   "source": [
    "This shows the top three passages that are relevant to the query. We can retrieve more results by changing the `k` value. The question in this simple demo is about Wikipedia because we know that the Wikipedia page is part of the documents in this subset of the archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_MODEL= \"cohere.command-r-plus-v1:0\"\n",
    "COMMAND_R_PLUS = \"cohere.command-r-plus-v1:0\"\n",
    "COMMAND_R = \"cohere.command-r-v1:0\"\n",
    "model_id = DEFAULT_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets import the required modules to run the notebook and set up the Bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3, json\n",
    "bedrock_rt = boto3.client(service_name=\"bedrock-runtime\", region_name = \"us-east-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3 - Configure the request to the model\n",
    "\n",
    "The developer provides a few things to the model:\n",
    "- A preamble containing instructions about the task and the desired style for the output.\n",
    "- The user request.\n",
    "- A list of tools to the model.\n",
    "- (Optionally) a chat history for the model to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia was founded by Jimmy Wales and Larry Sanger.\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Who founded Wikipedia.\"\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}],\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    response = bedrock_rt.converse(\n",
    "        modelId=DEFAULT_MODEL,\n",
    "        messages=conversation,\n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\n",
    "    )\n",
    "\n",
    "    # Extract and print the response text.\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
